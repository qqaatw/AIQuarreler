import os
import re
import glob
import json
import logging
from argparse import ArgumentParser


logging.getLogger().setLevel(logging.INFO)

class PTTDatasetBuilder():
    """Build TSV dataset from the json files generated by PttWebCrawler.

    Parameters
    ----------
    json_filenames : list
        Json filenames.
    base_dir : str
        The base directory to save TSV dataset.
    min_fetched_pushes : int, optional
        Minimal number of pushes, by default 5.
    """

    def __init__(self, json_filenames : list, base_dir, min_fetched_pushes=5):
        self.ptt_list = []
        self.base_dir = base_dir
        self.min_fetched_pushes = min_fetched_pushes
      
        os.makedirs(self.base_dir, exist_ok=True)

        for filename in glob.glob(json_filenames):
            with open(filename, 'r', encoding='utf8') as f:
                ptt_list = json.loads(f.read())
            self.ptt_list += ptt_list['articles']

    def _filter_content(self, ptt_list):
        return ptt_list

    def build_dataset(self, 
        tsv_filename='dataset.tsv',
        excluded_categories=None,
        included_categories=None,
        push_mode='thumb_up',
        use_push_arrow=True,
        use_content=False,
        start_from=None,
        **kwargs):
        """Build TSV dataset.

        Parameters
        ----------
        tsv_filename : str, optional
            Tsv filename, by default 'dataset.tsv'.
        excluded_categories : str or list, optional
            All categories will be used except for specified categories, E.g "討論,黑特". If not given, use all categories, by default None.
        included_categories : str or list, optional
            Only specified categories will be used, E.g "討論,黑特". If not given, use all categories, by default None.
        push_mode : str, optional
            Filter a specific push mode, available options: 'thumb_up', 'thumb_down' or 'both', by default 'thumb_up'.
        use_push_arrow : bool, optional
            Whether to use push_arrow, by default True.
        use_content : bool, optional
            Whether to use article content, by default False.
        start_from : str, optional
            Fetching the articles starting from YYYYMMDD. (not implemented yet.)
        """

        assert included_categories is None or excluded_categories is None, \
            'excluded_categories and included_categories are mutually exclusive.'
        if isinstance(included_categories, str):
            included_categories = included_categories.replace(' ', '').split(',') 
        if isinstance(excluded_categories, str):
            excluded_categories = excluded_categories.replace(' ', '').split(',')

        articles = self.ptt_list
        dataset = []
        for i, article in enumerate(articles, 1):
            try:
                title = article['article_title']
                if use_content:
                    content = article['content']
                else:
                    content = ''
                messages = []
                others = ''
                assert isinstance(title, str) and isinstance(content, str)
            except:
                logging.warning("Wrong title or content: {}, {}".format(title, content))
                continue

            if len(article['messages']) < self.min_fetched_pushes:
                continue

            if included_categories:
                match = re.search('|'.join(['\[{}\]'.format(category) for category in included_categories]), title)
                if not match:
                    continue
            elif excluded_categories:
                match = re.search('|'.join(['\[{}\]'.format(category) for category in excluded_categories]), title)
                if match:
                    continue
            
            for push_id, msg in enumerate(article['messages']):
                if push_id == self.min_fetched_pushes: break

                if msg['push_tag'] == '→' and use_push_arrow:
                    messages.append(msg['push_content'])
                    continue
                if push_mode == 'both':
                    messages.append(msg['push_contect'])
                elif (push_mode == 'thumb_up' and msg['push_tag'] == '推') or \
                    (push_mode == 'thumb_down' and msg['push_tag'] == '噓'):
                    messages.append(msg['push_content'])
            
            dataset.append('\t'.join([title, content, *messages, others]))

            if i % 100 == 0:
                logging.info('Processed articles: %d' % i)

        if not os.path.isdir(self.base_dir):
            os.mkdir(self.base_dir)
        with open(os.path.join(self.base_dir, tsv_filename), 'w', encoding='utf8') as f:
            tsv_title = '\t'.join(
                ['title',
                 'content', 
                 *["push_%d" % (i+1) for i in range(self.min_fetched_pushes)],
                 'others'])
            
            f.write(tsv_title + '\n')
            f.write('\n'.join(dataset))

def run(path, **kwargs):
    handler = PTTDatasetBuilder(path, base_dir=kwargs['base_dir'], min_fetched_pushes=kwargs['min_fetched_pushes'])
    handler.build_dataset(
        tsv_filename="{}.tsv".format(os.path.basename(path)),
        **kwargs)

if __name__ == "__main__":
    parser = ArgumentParser()

    parser.add_argument('-p', '--path', type=str, help='Json file path.', 
        required=True)
    parser.add_argument('--add_content', action='store_true', help='Whether to add article content.')

    parser.add_argument('--base_dir', type=str, help='Directory in which TSV datasets are stored.',
        default='./ptt_dataset')
    parser.add_argument('--min_fetched_pushes', type=int, help='Fetched articles that satisfy minimal pushes.',
        default=5)
    parser.add_argument('--start_from', type=str, help='Fetching the articles starting from YYYYMMDD. (not implemented yet.)',
        default=None)
    group = parser.add_mutually_exclusive_group()
    
    group.add_argument('-e', '--excluded_categories', type=str, 
        help='All categories will be used except the specified categories, E.g "討論,黑特". If not given, using all categories.',
        default=None)
    group.add_argument('-i', '--included_categories', type=str, 
        help='Only specified categories will be used, E.g "討論,黑特". If not given, using all categories.',
        default=None)

    args = parser.parse_args()

    run(**vars(args))